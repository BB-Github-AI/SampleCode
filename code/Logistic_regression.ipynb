{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Homework \\#8\n",
    "## <center> Logistic regression for tagging questions from StackOverflow\n",
    "\n",
    "**You have to infer some formulas where it is needed (yeah, you will need pen and paper), also you have to fill code where is is asked.**\n",
    "\n",
    "## 0. Description\n",
    "\n",
    "In this homework, we will study and program a model for predicting tags in the text of a question based on multiclass logistic regression. Unlike the usual statement of the classification problem (multiclass), in this case, one example can belong to several classes (multilabel) at the same time. We will implement the online version of the multilabel classification algorithm.\n",
    "\n",
    "We will use a small sample of tagged questions from the StackOverflow website with a size of 125 thousand examples (find in the `data/hw8` folder).\n",
    "\n",
    "\n",
    "PS: It can be shown that such an implementation is not at all effective and it would be easier to use vectorized calculations. For this dataset it is. But actually, such implementation is used in real life, but naturally, they are not written in Python. For example, a banner is shown to the user in the [CTR](https://en.wikipedia.org/wiki/Click-through_rate) forecasting online models, then, depending on the presence of a click, the model parameters are updated. In real life, the parameters of the model can be several hundred million. But usually, in such sparse data, not none parameters belonging to the user would be less than 100k. Often all this is stored in huge clusters in in-memory databases, and user processing is distributed.\n",
    "\n",
    "PS2:\n",
    "- in the process of solving homework, you will have to work with the text, and you may want to do obvious preprocessing, for example, put all the words in lower case, but  **you do not need to do this unless you are asked to do this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import gzip\n",
    "\n",
    "# BB Added\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# For math - Please uncomment - I had to comment as it caused my system to crash\n",
    "#from IPython.display import Math\n",
    "#from IPython.display import Latex\n",
    "\n",
    "# Set warnings off\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# change it to your location\n",
    "DS_FILE_NAME = './../../data/hw8/stackoverflow_sample_125k.tsv.gz'\n",
    "TAGS_FILE_NAME = './../../data/hw8/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'php', 'c#', 'c++', 'html', 'javascript', 'jquery', 'android', 'java', 'ios', 'python'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multiclass and Multilabel Logistic Regression\n",
    "\n",
    "\n",
    "Let's recap what is the Logistic Regression for binary classification $\\left\\{0, 1\\right\\}$. Probability that a sample belongs to a class $1$ can be inferred using [Bayes Formula](https://en.wikipedia.org/wiki/Bayes%27_theorem):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "where:\n",
    "- $\\vec{x}$ – features of the sample\n",
    "- $\\sigma$ – logistic sigmoid function\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – log odds is modelled by a linear function\n",
    "\n",
    "We can generalize it to a set of $K$ classes, only denominator will be changed in the Bayes Formula. Let's write down a probability of belonging to a class $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – a [softmax function](https://en.wikipedia.org/wiki/Softmax_function)\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – now instead of one line which separates two classes, we have several lines for each class $k$ which separates it from all others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [categorical disribution](https://en.wikipedia.org/wiki/Categorical_distribution) for a likelihood function, or it's log:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "This is well known [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) function (after multiplication to $-1$). Usually we maximize likelihood, but in the case of cross entropy we minimize it (because cross entropy is a measure between two distributions, and we want to move closer model distribution to a ground truth). To infer rule of updating weights we have to take a derivative wrt parameters, **plz do it if you have never done it before** (here is the solution [one](https://www.ics.uci.edu/~pjsadows/notes.pdf) and [two](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Vector of softmax values $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ forms a discrete probability distribution, i.e. $\\sum_{i=1}^K \\sigma_i = 1$. But in our setup each sample may have one or more tags, or belongs to one or more classes. We modify the model:\n",
    "- let's consider that each tag is independant from others, i.e. for each outcome we use binary logistic regression (either sample has the tag or not); then we can write down probabilities of a tag of the sample:\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- like in LR, presence of a tag we model by <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">Bernoulli distribution</a>\n",
    "\n",
    "<font color=\"red\">Question 1.</font> Your first task – is to infer and write down simplified loss function, which is negative log of likelihood of features of a sample $\\vec{x}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Options:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 2\n",
      "In the following, y represents the target label\n",
      "Moreover, based on the above assumption, each tag is independent from others\n",
      "and, for each outcome use binary logistic regression\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\mathcal{L} =  -\\log \\prod_{i=1}^K \\sigma (z_i)^{y_i} (1 - \\sigma(z_i))^{1 - y_i}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\mathcal{L} =  -\\sum_{i=1}^K \\log \\sigma (z_i)^{y_i} (1 - \\sigma(z_i))^{1 - y_i}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\mathcal{L} =  -\\sum_{i=1}^K y_i \\log \\sigma(z_i) + (1 - y_i) \\log (1 - \\sigma(z_i))$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# The solution \n",
    "print(\"Number 2 seems to be the solution\")\n",
    "print(\"In the following, y represents the target label\")\n",
    "print(\"Moreover, based on the above assumption, each tag is independent from others\")\n",
    "print(\"and, for each outcome use binary logistic regression\")\n",
    "\n",
    "Math(r'- \\mathcal{L} =  -\\log \\prod_{i=1}^K \\sigma (z_i)^{y_i} (1 - \\sigma(z_i))^{1 - y_i}')\n",
    "Math(r'- \\mathcal{L} =  -\\sum_{i=1}^K \\log \\sigma (z_i)^{y_i} (1 - \\sigma(z_i))^{1 - y_i}')\n",
    "Math(r'- \\mathcal{L} =  -\\sum_{i=1}^K y_i \\log \\sigma(z_i) + (1 - y_i) \\log (1 - \\sigma(z_i))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Update rule inference\n",
    "\n",
    "<font color=\"red\">Question 2.</font>Infer and write down an updating rule of parameters of the model, taking derivative of $-\\mathcal{L}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Options:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 2\n",
      "Suppose the following:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\mathcal{L} =  -\\sum_{i=1}^K y_i \\log \\sigma(z_i) + (1 - y_i) \\log (1 - \\sigma(z_i))$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle a = \\sigma(z_k)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle z_k = \\sum_{i=1}^M w_{ki} x^i$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\frac{\\partial \\mathcal{L}}{\\partial a}  \\frac{\\partial a}{\\partial z_k} \\frac{\\partial z_k}{\\partial w_{km}}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{\\partial \\mathcal{L}}{\\partial a}= - \\frac{y_k}{a} + \\frac{1-y_k}{1-a}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{\\partial a}{\\partial z_k}= a(1-a)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{\\partial z_k}{\\partial w_{km}}= x_m$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note the simplification: \n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle (\\frac{y_k}{a} + \\frac{1-y_k}{1-a})(a(1-a))= y_k-a$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hence\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}}= - x_m(y_k - \\sigma(z_k))$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"Number 2 seems to be the solution\")\n",
    "\n",
    "print(\"Suppose the following:\")\n",
    "Math(r'- \\mathcal{L} =  -\\sum_{i=1}^K y_i \\log \\sigma(z_i) + (1 - y_i) \\log (1 - \\sigma(z_i))')\n",
    "Math(r'a = \\sigma(z_k)')\n",
    "Math(r'z_k = \\sum_{i=1}^M w_{ki} x^i')\n",
    "\n",
    "#print(\"Chain Rule seems helpful\")\n",
    "Math(r'\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\frac{\\partial \\mathcal{L}}{\\partial a}  \\frac{\\partial a}{\\partial z_k} \\frac{\\partial z_k}{\\partial w_{km}}')\n",
    "Math(r'\\frac{\\partial \\mathcal{L}}{\\partial a}= - \\frac{y_k}{a} + \\frac{1-y_k}{1-a}')\n",
    "Math(r'\\frac{\\partial a}{\\partial z_k}= a(1-a)')\n",
    "Math(r'\\frac{\\partial z_k}{\\partial w_{km}}= x_m')\n",
    "print(\"Note the simplification: \")        \n",
    "Math(r'(\\frac{y_k}{a} + \\frac{1-y_k}{1-a})(a(1-a))= y_k-a')\n",
    "print(\"Hence\")\n",
    "Math(r'-\\frac{\\partial \\mathcal{L}}{\\partial w_{km}}= - x_m(y_k - \\sigma(z_k))')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementation of the base model\n",
    "\n",
    "### Shortest introduction to text processing\n",
    "\n",
    "<img src='./../../img/Bag-Of-Words-BOW-representation-of-the-input-that-is-next-follow-by-Softmax.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the base class\n",
    "\n",
    "In this exercise, you have a facade of the class, study it carefully, pay attention to all comments in the code. Then plz fill gaps in the code where is it asked.\n",
    "\n",
    "As you may notice from the code, for updating parameter $w_{km}$ we use only feature $x_m$, which equals to $0$ if there is now word with index $m$ in the sentence, and greater then $0$ if there is such word. In our case, if we don't want to recalculate [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) for the incoming sentence, we are iterating over words of the sentence in the order of the sentence. If a word occurs several times, then we add it to the cummolative variable with its weight. **When you accumulate linear combination of words and parameters in $z$, you should count only non-zero features of an object.**\n",
    "\n",
    "Hint:\n",
    "- if you implement calculation of the sigmoid function in a straightforward way like in formula, then big negative $z$ will give you large value of $e^{-z}$ which may exceed limits of `float32`\n",
    "- meanwhile $e^{-z}$ of big positive $z$ will be zero\n",
    "- use properties of $\\sigma$ to fix this numerical issue, to avoid overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "   \n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # dictionary which conains mapping from words to indices (to save memory)\n",
    "        # e.g. self._vocab['exception'] = 17 means that word `exception` has index equal to 17\n",
    "        self._vocab = {}\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        self._tags = set(tags)\n",
    "  \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # open gzipped text file\n",
    "        with gzip.open(fname, 'rb') as f:\n",
    "            \n",
    "            # iterate over lines in the file\n",
    "            for line in tqdm(f, total=total, mininterval=1):\n",
    "                pair = line.decode().strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                                \n",
    "                # words of the sentence, these are features x\n",
    "                sentence = sentence.split(' ')\n",
    "                # tags of the sentence, these are targets y\n",
    "                tags = set(tags.split(' '))                \n",
    "                                \n",
    "                # loss of the current sample\n",
    "                sample_loss = 0\n",
    "                \n",
    "                # calculate gradients and update weights\n",
    "                # iterate over tags, because each tag has its own list of parameters\n",
    "                for tag in self._tags:\n",
    "                    # target variable is 1 if a tag is in the set of tags of the current sentence\n",
    "                    y = int(tag in tags)\n",
    "                      \n",
    "                    z=self._b[tag] \n",
    "                                                           \n",
    "                    for word in sentence:\n",
    "                        \n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        \n",
    "                        z += self._w[tag][self._vocab[word]] \n",
    "                    \n",
    "                    sigma = 1/(1 + np.exp(-z)) if z >= 0 else  np.exp(z)/(np.exp(z) + 1)\n",
    "                    \n",
    "                    # Similar to notes, lecture 8\n",
    "                    sample_loss += -y * np.log(max([tolerance, sigma])) if y == 1 else -(1 - y) * np.log(1 - min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    # if we are in the training part of the dataset, we update weights\n",
    "                    if n < top_n_train:\n",
    "                        dLdw = y - sigma\n",
    "                        # update weights\n",
    "                        # we minimize negatime log likelihood (the second minus sign)\n",
    "                        # why we follow negative direction of the gradient (the first minus sign)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1                  \n",
    "                self._loss.append(sample_loss)\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125000/125000 [04:08<00:00, 503.70it/s] \n"
     ]
    }
   ],
   "source": [
    "# let's create an instance of the object and iterate through dataset \n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the value of the negative log likelihood really decreased. Since we use stochastic gradient descent, we should not expect a smooth fall in the error function. We will use a moving average with a window of 10 thousand examples to somehow smooth out the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 20.09\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Question 3.</font>\n",
    "Calculate mean value of the loss function on the last 10 000 examples of testing set. Choose the closest answer to yours from he following list.\n",
    "\n",
    "<font color=\"red\">Options:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. 19.74\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 4 seems closest, as the output was 20.09\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer 4 seems closest, as the output was 20.09\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "In the base model we used first 100 000 line for training, and the rest for testing. As you may see, value of negative log likelihood is not very informative. You have to modify the base model, such that `iterate_file` would return value of _accuracy_ on the test set. \n",
    "\n",
    "We define accuracy as:\n",
    "- we consider a threshold equal to `0.9`, if the predicted probability of a tag is greater then the threshold, we consder that the input sentence has the tag\n",
    "- we calculate accuracy using [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index) between the set of predicted tags and the set of ground truth tags\n",
    "  - e.g. if a sentence has two tags ['html', 'jquery'], but model predicted three ['ios', 'html', 'java'], then Jaccard index equals to |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- method `iterate_file` returns **average** accuracy on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    def __init__(self, tags=top_tags):      \n",
    "        \n",
    "        self._vocab = {}\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        self._tags = set(tags)\n",
    "        \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        threshold = 0.9\n",
    "        testJacc = []\n",
    "                \n",
    "        # open gzipped text file\n",
    "        with gzip.open(fname, 'rb') as f:            \n",
    "            \n",
    "            for line in tqdm(f, total=total, mininterval=1):\n",
    "                pair = line.decode().strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                                \n",
    "                sentence = sentence.split(' ')\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                sample_loss = 0\n",
    "                pTag = []\n",
    "                \n",
    "                for tag in self._tags:                  \n",
    "                    y = int(tag in tags)\n",
    "                    z=self._b[tag] \n",
    "                                                                                                  \n",
    "                    for word in sentence:                        \n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                       \n",
    "                        z += self._w[tag][self._vocab[word]] \n",
    "                                            \n",
    "                    sigma = 1/(1 + np.exp(-z)) if z >= 0 else  np.exp(z)/(np.exp(z) + 1)                    \n",
    "                    sample_loss += -y * np.log(max([tolerance, sigma])) if y == 1 \\\n",
    "                    else -(1 - y) * np.log(1 - min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    if n < top_n_train:\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                    else:\n",
    "                        #print(\"n is\", n, \"sigma is \", sigma, \"y is \", y, \"tag is \", tag)\n",
    "                        if sigma > threshold:\n",
    "                            pTag.append(tag)\n",
    "                            #print(\"tag array is\", pTag)\n",
    "                \n",
    "                # For one entry in the file, focus on tags \n",
    "                if n >= top_n_train:                   \n",
    "                    pTag = set(pTag)\n",
    "                    jacc = len(tags.intersection(pTag)) / len(tags.union(pTag))\n",
    "                    testJacc.append(jacc)\n",
    "                                \n",
    "                n += 1\n",
    "                self._loss.append(sample_loss)\n",
    "        \n",
    "        # According to wikipedia, if both sets are empty we return 1   \n",
    "        avgAcc = float(sum(testJacc)/len(testJacc)) #if len(testJacc) > 0 else 1\n",
    "        return avgAcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125000/125000 [04:01<00:00, 516.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accurace returned by the above is\n",
      "0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "#model.iterate_file()\n",
    "acc = model.iterate_file()\n",
    "# print accuracy\n",
    "print(\"The accurace returned by the above is\")\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Question 4.</font> Find the closest answer to the printed accuracy from the following list?\n",
    "\n",
    "<font color=\"red\">Options:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer number 3 is closest\n"
     ]
    }
   ],
   "source": [
    "print(\"The answer number 3 is closest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-regilarization\n",
    "\n",
    "Your fifth task is to upgrade the model `LogRegressor` such that it would support $L_2$-regularization. In the method `iterate_file` should be rarameter `lmbda=0.01` with the default value. Takin into account regilarization, new loss function wil be:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Gradient of the first term we have already inferred, for the second one it is:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "If we would regularize ALL weights for each sentence we will slow down the process dramatically, because we will need to iterate over vacabulary for each sentence. But we will use dirty trick from real life, which would drop quality a bit, but boost computational performace: we will apply rerularization only for such parameters which correspondant words are presented in the sentence. Don't forget, that we don't regularize bias/w_0. Also do not modify `sample_loss`, calculate it without regularization.\n",
    "\n",
    "Hint:\n",
    "- don't forget, that you need to regularize parameter once, even if there were several correspondant words\n",
    "- let's agree to regularize a parameter, only if we see its word for a first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    def __init__(self, tags=top_tags):      \n",
    "        \n",
    "        self._vocab = {}\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        self._tags = set(tags)\n",
    "        \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda=0.01):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        threshold = 0.9\n",
    "        testJacc = []\n",
    "                \n",
    "        # open gzipped text file\n",
    "        with gzip.open(fname, 'rb') as f:            \n",
    "            \n",
    "            for line in tqdm(f, total=total, mininterval=1):\n",
    "                pair = line.decode().strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                                \n",
    "                sentence = sentence.split(' ')\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                sample_loss = 0\n",
    "                pTag = []\n",
    "                \n",
    "                for tag in self._tags:                  \n",
    "                    y = int(tag in tags)\n",
    "                    z=self._b[tag] \n",
    "                                                                                                  \n",
    "                    for word in sentence:                        \n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                       \n",
    "                        z += self._w[tag][self._vocab[word]] \n",
    "                                            \n",
    "                    sigma = 1/(1 + np.exp(-z)) if z >= 0 else  np.exp(z)/(np.exp(z) + 1)                    \n",
    "                    sample_loss += -y * np.log(max([tolerance, sigma])) if y == 1 \\\n",
    "                    else -(1 - y) * np.log(1 - min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    if n < top_n_train:                     \n",
    "                        \n",
    "                        dLdw = y - sigma\n",
    "                                                \n",
    "                        wordset=set()\n",
    "                        for word in sentence: \n",
    "                            # let's agree to regularize a parameter, only if we see its word for a first time\n",
    "                            if word not in wordset:\n",
    "                                wordset.add(word)\n",
    "                                oldWt = self._w[tag][self._vocab[word]]\n",
    "                                self._w[tag][self._vocab[word]] -= -learning_rate*dLdw + (learning_rate * lmbda * oldWt)\n",
    "                        \n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                    else:\n",
    "                        #print(\"n is\", n, \"sigma is \", sigma, \"y is \", y, \"tag is \", tag)\n",
    "                        if sigma > threshold:\n",
    "                            pTag.append(tag)\n",
    "                            #print(\"tag array is\", pTag)\n",
    "                \n",
    "                # For one entry in the file, focus on tags \n",
    "                if n >= top_n_train:                   \n",
    "                    pTag = set(pTag)\n",
    "                    jacc = len(tags.intersection(pTag)) / len(tags.union(pTag))\n",
    "                    testJacc.append(jacc)\n",
    "                                \n",
    "                n += 1\n",
    "                self._loss.append(sample_loss)\n",
    "        \n",
    "        # According to wikipedia, if both sets are empty we return 1   \n",
    "        avgAcc = float(sum(testJacc)/len(testJacc)) #if len(testJacc) > 0 else 1\n",
    "        return avgAcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125000/125000 [04:20<00:00, 479.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Question 5.</font> Find the closest answer to the printed accuracy from the following list?\n",
    "\n",
    "<font color=\"red\">Options:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 4 seems closest\n"
     ]
    }
   ],
   "source": [
    "print(\"Option 4 seems closest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet Regularization, formulas\n",
    "Beside $L_2$ regularization, $L_1$ is used quite often.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "ElasticNet is a linear combination of $L_1$ and $L_2$:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- where $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "<font color=\"red\">Question 6.</font> Find a gradient of ElasticNet (do not take into account $-\\mathcal{L}$ for now). \n",
    "\n",
    "<font color=\"red\">Options:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer number 3 is correct and calculation seems straight forward, hence excluded\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer number 3 is correct and calculation seems straight forward, hence excluded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ElasticNet Regularization, implementation\n",
    "\n",
    "Please update `LogRegressor` so that it would support `ElasticNet`. Method `iterate_file` now should take `lmbda=0.0002` and `gamma=0.1`. Run one pass over dataset with `ElasticNet` and default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    def __init__(self, tags=top_tags):      \n",
    "        \n",
    "        self._vocab = {}\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        self._tags = set(tags)\n",
    "        \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma = 0.1):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        threshold = 0.9\n",
    "        testJacc = []\n",
    "                \n",
    "        # open gzipped text file\n",
    "        with gzip.open(fname, 'rb') as f:            \n",
    "            \n",
    "            for line in tqdm(f, total=total, mininterval=1):\n",
    "                pair = line.decode().strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                                \n",
    "                sentence = sentence.split(' ')\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                sample_loss = 0\n",
    "                pTag = []\n",
    "                \n",
    "                for tag in self._tags:                  \n",
    "                    y = int(tag in tags)\n",
    "                    z=self._b[tag] \n",
    "                                                                                                  \n",
    "                    for word in sentence:                        \n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                       \n",
    "                        z += self._w[tag][self._vocab[word]] \n",
    "                                            \n",
    "                    sigma = 1/(1 + np.exp(-z)) if z >= 0 else  np.exp(z)/(np.exp(z) + 1)                    \n",
    "                    sample_loss += -y * np.log(max([tolerance, sigma])) if y == 1 \\\n",
    "                                               else -(1 - y) * np.log(1 - min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    if n < top_n_train:                     \n",
    "                        \n",
    "                        dLdw = y - sigma                                                \n",
    "                        \n",
    "                        for word in sentence: \n",
    "                            oldWt = self._w[tag][self._vocab[word]]\n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw + \\\n",
    "                                                                (learning_rate*lmbda*2*gamma*oldWt) + \\\n",
    "                                                                (learning_rate*lmbda*(1-gamma)*np.sign(oldWt))  \n",
    "                        \n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                    else:\n",
    "                        #print(\"n is\", n, \"sigma is \", sigma, \"y is \", y, \"tag is \", tag)\n",
    "                        if sigma > threshold:\n",
    "                            pTag.append(tag)\n",
    "                            #print(\"tag array is\", pTag)\n",
    "                \n",
    "                # For one entry in the file, focus on tags \n",
    "                if n >= top_n_train:                   \n",
    "                    pTag = set(pTag)\n",
    "                    jacc = len(tags.intersection(pTag)) / len(tags.union(pTag))\n",
    "                    testJacc.append(jacc)\n",
    "                                \n",
    "                n += 1\n",
    "                self._loss.append(sample_loss)\n",
    "        \n",
    "        # According to wikipedia, if both sets are empty we return 1   \n",
    "        avgAcc = float(sum(testJacc)/len(testJacc)) #if len(testJacc) > 0 else 1\n",
    "        return avgAcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125000/125000 [12:47<00:00, 162.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Question 7.</font> Find the closest answer to the printed accuracy from the following list?\n",
    "\n",
    "<font color=\"red\">Options:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest answer is number 1, as the returned value is 0.60\n"
     ]
    }
   ],
   "source": [
    "print(\"The closest answer is number 1, as the returned value is 0.60\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Most important words for a tag\n",
    "\n",
    "Linear models are easy to interpretate. Please find the most important words for each tag and answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "#model._vocab_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "php : php, x5c, echo, 125, _post\n",
      "c# : writeline, binding, linq, net, foreach\n",
      "c++ : avrf, c++, std, cout, cpp\n",
      "html : 3, html, br, nav, try\n",
      "javascript : javascript, x20, 3, 125, x30\n",
      "jquery : jquery, ready, ajax, span, val\n",
      "android : android, activity, imgsrv, 29297, 18\n",
      "java : servlet, println, spring, hibernate, bean\n",
      "ios : ios, dylib, nil, nsstring, corefoundation\n",
      "python : python, def, py, django, np\n"
     ]
    }
   ],
   "source": [
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Question 8.</font> For many tags, the presence of the tag itself in the sentence is an important signal, for them the tag itself is the strongest signal, which is not surprising. For which of the tags is the set of tags, the name of the tag itself is not in the top 5 most important?\n",
    "\n",
    "<font color=\"red\">Options:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is c#\n"
     ]
    }
   ],
   "source": [
    "print(\"The answer is c#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Reduce the size of the vacabulary\n",
    "Currently we have 519290 words in the vacabulary. If it would be full StackOverflow dump, there would be 10 millions of words. We can regularize models not only using mathematics (e.g. `L1` and `L2`), but using empirical knowledge. For example we know that there are many stop words, emojis and just non informative words. So let's reduce ste size of the vacabulary manually.\n",
    "\n",
    "Your job is to modify `LogRegressor`:\n",
    "- add to the method `iterate_file` one more argument with default value `update_vocab=True`\n",
    "- with `update_vocab=True` model can add new words to the vacabulary\n",
    "- with `update_vocab=False` model should ignore all words which are not presented in the vacabulary\n",
    "- add method `filter_vocab(n=10000)`, which would keep only top-n most popular words using data from `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW\n",
    "class LogRegressor():\n",
    "    \n",
    "    def __init__(self, tags=top_tags):      \n",
    "        \n",
    "        self._vocab = {}\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        self._tags = set(tags)\n",
    "        self._wordCount = defaultdict(int)   \n",
    "     \n",
    "    \n",
    "    def filter_vocab(self, n=10000):\n",
    "        \n",
    "        # Find the most frequent words that we want to keep\n",
    "        sortedNWords = set([k for (k, v) in sorted(self._wordCount.items(), key=lambda item: item[1], reverse=True)[:n]])\n",
    "        # Filter vocab dictionary, based on words\n",
    "        self._vocab = dict([(k, v) for (k, v) in self._vocab.items() if k in sortedNWords])\n",
    "        # Change voccab to set\n",
    "        vocabSet = set([v for (k, v) in self._vocab.items()])\n",
    "        # Filter weights based on keys\n",
    "        for tag in self._tags:\n",
    "            self._w[tag] = dict([(k, v) for (k, v) in self._w[tag].items() if k in vocabSet])\n",
    "    \n",
    "        \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma = 0.1,\n",
    "                     update_vocab=True):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        threshold = 0.9\n",
    "        testJacc = []\n",
    "                \n",
    "        # open gzipped text file\n",
    "        with gzip.open(fname, 'rb') as f:            \n",
    "            \n",
    "            for line in tqdm(f, total=total, mininterval=1):\n",
    "                pair = line.decode().strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                                \n",
    "                sentence = sentence.split(' ')\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                sample_loss = 0\n",
    "                pTag = []\n",
    "                \n",
    "                for tag in self._tags:                  \n",
    "                    y = int(tag in tags)\n",
    "                    z=self._b[tag] \n",
    "                                                                                                  \n",
    "                    for word in sentence:                        \n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if update_vocab==False and word not in self._vocab:\n",
    "                            continue\n",
    "                        if update_vocab == True:\n",
    "                            if word not in self._vocab:\n",
    "                                self._vocab[word] = len(self._vocab)\n",
    "                            self._wordCount[word] = self._wordCount[word] +  1\n",
    "                            \n",
    "                        z += self._w[tag][self._vocab[word]]                    \n",
    "                                       \n",
    "                    sigma = 1/(1 + np.exp(-z)) if z >= 0 else  np.exp(z)/(np.exp(z) + 1)                    \n",
    "                    sample_loss += -y * np.log(max([tolerance, sigma])) if y == 1 \\\n",
    "                                               else -(1 - y) * np.log(1 - min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    if n < top_n_train:                     \n",
    "                        \n",
    "                        dLdw = y - sigma                                                \n",
    "                        \n",
    "                        for word in sentence: \n",
    "                            if word not in self._vocab:\n",
    "                                continue\n",
    "                            oldWt = self._w[tag][self._vocab[word]]\n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw + \\\n",
    "                                                                (learning_rate*lmbda*2*gamma*oldWt) + \\\n",
    "                                                                (learning_rate*lmbda*(1-gamma)*np.sign(oldWt))  \n",
    "                        \n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                    else:\n",
    "                        #print(\"n is\", n, \"sigma is \", sigma, \"y is \", y, \"tag is \", tag)\n",
    "                        if sigma > threshold:\n",
    "                            pTag.append(tag)\n",
    "                            #print(\"tag array is\", pTag)\n",
    "                \n",
    "                # For one entry in the file, focus on tags \n",
    "                if n >= top_n_train:                   \n",
    "                    pTag = set(pTag)\n",
    "                    jacc = len(tags.intersection(pTag)) / len(tags.union(pTag))\n",
    "                    testJacc.append(jacc)\n",
    "                                \n",
    "                n += 1\n",
    "                self._loss.append(sample_loss)\n",
    "        \n",
    "        # According to wikipedia, if both sets are empty we return 1   \n",
    "        avgAcc = float(sum(testJacc)/len(testJacc)) #if len(testJacc) > 0 else 1\n",
    "        return avgAcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Showing the weights\")\n",
    "#first100pairsW = {k: model._wordCount[k] for k in list(model._wordCount)[100]}\n",
    "#first100pairsW\n",
    "\n",
    "#model.filter_vocab(n=5)\n",
    "#model._vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx={0:2, 1:4, 2:1, 3:50, 4:20, 5:90, 6:22}\\ny={1:0, 5:1, 3:4}\\nsortedNWords = set([k for (k,v) in sorted(x.items(), key=lambda item: item[1], reverse=True)[:5]])\\nsortedNWords\\ny = dict([(k, v) for (k, v) in y.items() if v in sortedNWords])\\ny\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "x={0:2, 1:4, 2:1, 3:50, 4:20, 5:90, 6:22}\n",
    "y={1:0, 5:1, 3:4}\n",
    "sortedNWords = set([k for (k,v) in sorted(x.items(), key=lambda item: item[1], reverse=True)[:5]])\n",
    "sortedNWords\n",
    "y = dict([(k, v) for (k, v) in y.items() if v in sortedNWords])\n",
    "y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx1={0:1,2:3,4:5}\\nx2={1:6, 3:8, 5:40, 7:10}\\n\\nx2 = dict([(k, v) for (k, v) in x2.items() if x1.has_key(v)])\\nx2\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "x1={0:1,2:3,4:5}\n",
    "x2={1:6, 3:8, 5:40, 7:10}\n",
    "\n",
    "x2 = dict([(k, v) for (k, v) in x2.items() if x1.has_key(v)])\n",
    "x2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125000/125000 [13:02<00:00, 159.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's keep only 10 000 words\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125000/125000 [11:33<00:00, 180.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do one more pass over dataset, with reduced learning rate\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Question 9.</font> Find the closest answer to the printed accuracy from the following list? \n",
    "\n",
    "<font color=\"red\">Options:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The closest answer is number 3, as the returned value is 0.69\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Predic tags for a new question\n",
    "\n",
    "The last task is to write a function `predict_proba`, which take a string as input, returns a list of predicted tags with their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Code\n",
    "\n",
    "### NEW\n",
    "class LogRegressor():\n",
    "    \n",
    "    def __init__(self, tags=top_tags):      \n",
    "        \n",
    "        self._vocab = {}\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        self._tags = set(tags)\n",
    "        self._wordCount = defaultdict(int)   \n",
    "     \n",
    "    \n",
    "    def filter_vocab(self, n=10000):\n",
    "        \n",
    "        # Find the most frequent words that we want to keep\n",
    "        sortedNWords = set([k for (k, v) in sorted(self._wordCount.items(), key=lambda item: item[1], reverse=True)[:n]])\n",
    "        # Filter vocab dictionary, based on words\n",
    "        self._vocab = dict([(k, v) for (k, v) in self._vocab.items() if k in sortedNWords])\n",
    "        # Change voccab to set\n",
    "        vocabSet = set([v for (k, v) in self._vocab.items()])\n",
    "        # Filter weights based on keys\n",
    "        for tag in self._tags:\n",
    "            self._w[tag] = dict([(k, v) for (k, v) in self._w[tag].items() if k in vocabSet])\n",
    "   \n",
    "    \n",
    "    def predict_proba(self,sample):        \n",
    "        \n",
    "        #pTag = defaultdict(float)\n",
    "        pTag={}\n",
    "        sentence = sample.split(' ')\n",
    "        \n",
    "        for tag in self._tags:\n",
    "            z = self._b[tag]\n",
    "            for word in sentence:\n",
    "                if word not in self._vocab:\n",
    "                    continue\n",
    "                z += self._w[tag][self._vocab[word]]\n",
    "            sigma = 1/(1 + np.exp(-z)) if z >= 0 else  np.exp(z)/(np.exp(z) + 1)\n",
    "            pTag[tag] = sigma\n",
    "    \n",
    "        return pTag\n",
    "    \n",
    "        \n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma = 0.1,\n",
    "                     update_vocab=True):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        threshold = 0.9\n",
    "        testJacc = []\n",
    "                \n",
    "        # open gzipped text file\n",
    "        with gzip.open(fname, 'rb') as f:            \n",
    "            \n",
    "            for line in tqdm(f, total=total, mininterval=1):\n",
    "                pair = line.decode().strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                                \n",
    "                sentence = sentence.split(' ')\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                sample_loss = 0\n",
    "                pTag = []\n",
    "                \n",
    "                for tag in self._tags:                  \n",
    "                    y = int(tag in tags)\n",
    "                    z=self._b[tag] \n",
    "                                                                                                  \n",
    "                    for word in sentence:                        \n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if update_vocab==False and word not in self._vocab:\n",
    "                            continue\n",
    "                        if update_vocab == True:\n",
    "                            if word not in self._vocab:\n",
    "                                self._vocab[word] = len(self._vocab)\n",
    "                            self._wordCount[word] = self._wordCount[word] +  1\n",
    "                            \n",
    "                        z += self._w[tag][self._vocab[word]]                    \n",
    "                                       \n",
    "                    sigma = 1/(1 + np.exp(-z)) if z >= 0 else  np.exp(z)/(np.exp(z) + 1)                    \n",
    "                    sample_loss += -y * np.log(max([tolerance, sigma])) if y == 1 \\\n",
    "                                               else -(1 - y) * np.log(1 - min([1 - tolerance, sigma]))\n",
    "                    \n",
    "                    if n < top_n_train:                     \n",
    "                        \n",
    "                        dLdw = y - sigma                                                \n",
    "                        \n",
    "                        for word in sentence: \n",
    "                            if word not in self._vocab:\n",
    "                                continue\n",
    "                            oldWt = self._w[tag][self._vocab[word]]\n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw + \\\n",
    "                                                                (learning_rate*lmbda*2*gamma*oldWt) + \\\n",
    "                                                                (learning_rate*lmbda*(1-gamma)*np.sign(oldWt))  \n",
    "                        \n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                    else:\n",
    "                        #print(\"n is\", n, \"sigma is \", sigma, \"y is \", y, \"tag is \", tag)\n",
    "                        if sigma > threshold:\n",
    "                            pTag.append(tag)\n",
    "                            #print(\"tag array is\", pTag)\n",
    "                \n",
    "                # For one entry in the file, focus on tags \n",
    "                if n >= top_n_train:                   \n",
    "                    pTag = set(pTag)\n",
    "                    jacc = len(tags.intersection(pTag)) / len(tags.union(pTag))\n",
    "                    testJacc.append(jacc)\n",
    "                                \n",
    "                n += 1\n",
    "                self._loss.append(sample_loss)\n",
    "        \n",
    "        # According to wikipedia, if both sets are empty we return 1   \n",
    "        avgAcc = float(sum(testJacc)/len(testJacc)) #if len(testJacc) > 0 else 1\n",
    "        return avgAcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125000/125000 [13:27<00:00, 154.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125000/125000 [11:03<00:00, 188.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ios', 0.9999999999969442),\n",
       " ('php', 0.9999997996950653),\n",
       " ('android', 0.1478174432088049),\n",
       " ('java', 6.543014207693596e-21),\n",
       " ('c++', 1.340824478855083e-21),\n",
       " ('html', 1.2600399510847358e-21),\n",
       " ('javascript', 1.0689539724003366e-23),\n",
       " ('c#', 5.408022898558134e-33),\n",
       " ('python', 5.585024650219567e-40),\n",
       " ('jquery', 4.060872911919363e-49)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Choose all tags, using threshold equal to $0.9$. \n",
    "\n",
    "<font color=\"red\">Options (multiple):</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The tags seem to be ios, php\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
